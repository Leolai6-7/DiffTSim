{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "16cWJcn88e2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHVnmrXbNCLB"
      },
      "outputs": [],
      "source": [
        "#!pip install -q -U einops datasets matplotlib tqdm\n",
        "\n",
        "import math\n",
        "from inspect import isfunction\n",
        "from functools import partial\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from einops import rearrange, reduce\n",
        "#from einops.layers.torch import Rearrange\n",
        "\n",
        "import torch\n",
        "from torch import nn, einsum\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDbIxf0YlHVE"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from einops import rearrange  # 假设已经导入了einops库中的rearrange函数\n",
        "#from torch_utils import exists  # 假设已经定义了exists函数，用于检查对象是否存在\n",
        "\n",
        "# 自行定义exists函数，用于检查对象是否存在（非None）\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "# 定義一個基礎的Block塊\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, dim, dim_out, groups=8):\n",
        "        super().__init__()\n",
        "        # 修改為1D卷積，kernel size依據需要設定\n",
        "        self.proj = nn.Conv1d(dim, dim_out, 3, padding=1)\n",
        "        self.norm = nn.GroupNorm(groups, dim_out)\n",
        "        self.act = nn.SiLU()\n",
        "\n",
        "    def forward(self, x, scale_shift=None):\n",
        "        x = self.proj(x)  # 卷積操作\n",
        "        # print(\"進入 GroupNorm 前的 x 形狀:\", x.shape)\n",
        "        x = self.norm(x)  # 進行GroupNorm\n",
        "        if exists(scale_shift):\n",
        "            scale, shift = scale_shift\n",
        "            x = x * (scale + 1) + shift\n",
        "        x = self.act(x)  # 激活函數\n",
        "        return x\n",
        "\n",
        "\n",
        "# 定义一个ResnetBlock类，用于构建残差网络中的基本块\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim, dim_out, *, time_emb_dim=None, groups=8):\n",
        "        super().__init__()\n",
        "        #如果有time_emb＿dim存在,用一個mlp處理時間嵌入\n",
        "        self.mlp = (\n",
        "            nn.Sequential(nn.SiLU(), nn.Linear(time_emb_dim, dim_out))\n",
        "            if exists(time_emb_dim)\n",
        "            else None\n",
        "        )\n",
        "        #用兩個基礎模塊處裡時續數據\n",
        "        self.block1 = Block(dim, dim_out, groups=groups)\n",
        "        self.block2 = Block(dim_out, dim_out, groups=groups)\n",
        "        #如果輸入與輸出維度不同,用Conv1d調整\n",
        "        self.res_conv = nn.Conv1d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x, time_emb=None):\n",
        "        h = self.block1(x)\n",
        "        if exists(self.mlp) and exists(time_emb):\n",
        "            time_emb = self.mlp(time_emb)\n",
        "            # 注意，這裡調整成1D格式\n",
        "            #直接將time_emb用broadcast的方式\n",
        "\n",
        "            h = rearrange(time_emb, \"b c -> b c 1\") + h\n",
        "        h = self.block2(h)\n",
        "        return h + self.res_conv(x)\n",
        "#將 x = (batch_size, dim, time_steps)轉成 (batch_size, dim＿out, time_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKxTiggqlHVE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from einops import rearrange\n",
        "\n",
        "# 定义标准的多头注意力机制类\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads=4, dim_head=32):\n",
        "        super().__init__()\n",
        "        # 对查询向量进行缩放，以避免梯度消失问题\n",
        "        self.scale = dim_head ** -0.5\n",
        "        # 多头注意力的头数\n",
        "        self.heads = heads\n",
        "        # 计算多头注意力层的隐藏维度大小\n",
        "        hidden_dim = dim_head * heads\n",
        "        # 使用1D卷积层将输入映射到 QKV（查询、键、值）空间\n",
        "        # 输出的通道数是3倍的hidden_dim，分别对应 Q、K、V\n",
        "        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)\n",
        "        # 定义输出层，使用1D卷积将注意力的输出映射回输入维度\n",
        "        self.to_out = nn.Conv1d(hidden_dim, dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 输入的x张量形状为 (batch, features, time)\n",
        "        b, c, t = x.shape\n",
        "        # 通过卷积层获取 Q、K、V 三个张量，分别对应查询、键和值\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=1)  # 将卷积结果按通道维度切割为3部分\n",
        "\n",
        "        # 使用Einops将Q、K、V重排为适合注意力计算的形状\n",
        "        # 形状变为 (batch, heads, 每个头的特征维度, time)\n",
        "        q, k, v = map(\n",
        "            lambda t: rearrange(t, \"b (h c) t -> b h c t\", h=self.heads), qkv\n",
        "        )\n",
        "\n",
        "        # 缩放查询向量\n",
        "        q = q * self.scale\n",
        "\n",
        "        # 计算查询和键之间的相似度分数（注意力分数）\n",
        "        sim = torch.einsum(\"b h d i, b h d j -> b h i j\", q, k)\n",
        "\n",
        "        # 为了数值稳定性，从相似度分数中减去最大值\n",
        "        sim = sim - sim.amax(dim=-1, keepdim=True).detach()\n",
        "\n",
        "        # 对相似度分数应用Softmax，得到注意力权重\n",
        "        attn = sim.softmax(dim=-1)\n",
        "\n",
        "        # 使用注意力权重对值（V）进行加权\n",
        "        out = torch.einsum(\"b h i j, b h d j -> b h i d\", attn, v)\n",
        "\n",
        "        # 将输出重排回 (batch, heads * 每个头的特征维度, time) 的形式\n",
        "        out = rearrange(out, \"b h t d -> b (h d) t\")\n",
        "\n",
        "        # 通过输出卷积层映射回输入维度，返回结果\n",
        "        return self.to_out(out)\n",
        "\n",
        "# 定义线性注意力机制类\n",
        "class LinearAttention(nn.Module):\n",
        "    def __init__(self, dim, heads=4, dim_head=32):\n",
        "        super().__init__()\n",
        "        # 对查询向量进行缩放\n",
        "        self.scale = dim_head ** -0.5\n",
        "        # 多头注意力的头数\n",
        "        self.heads = heads\n",
        "        # 计算多头注意力层的隐藏维度大小\n",
        "        hidden_dim = dim_head * heads\n",
        "        # 使用1D卷积层将输入映射到 QKV 空间\n",
        "        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)\n",
        "        # 定义输出层，将注意力的输出映射回输入维度，并使用GroupNorm归一化\n",
        "        self.to_out = nn.Sequential(nn.Conv1d(hidden_dim, dim, 1),\n",
        "                                    nn.GroupNorm(1, dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 输入的x张量形状为 (batch, features, time)\n",
        "        b, c, t = x.shape\n",
        "        # 通过卷积层获取 Q、K、V 三个张量\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=1)  # 按通道维度分割\n",
        "\n",
        "        # 使用Einops将Q、K、V重排为适合注意力计算的形状\n",
        "        q, k, v = map(\n",
        "            lambda t: rearrange(t, \"b (h c) t -> b h c t\", h=self.heads), qkv\n",
        "        )\n",
        "\n",
        "        # 对Q、K分别进行softmax操作，Q在通道维度，K在时间维度\n",
        "        q = q.softmax(dim=-2)\n",
        "        k = k.softmax(dim=-1)\n",
        "        # 缩放查询向量\n",
        "        q = q * self.scale\n",
        "\n",
        "        # 计算键和值的加权组合，得到上下文矩阵\n",
        "        context = torch.einsum(\"b h d n, b h e n -> b h d e\", k, v)\n",
        "\n",
        "        # 使用上下文矩阵对查询向量进行加权\n",
        "        out = torch.einsum(\"b h d e, b h d n -> b h e n\", context, q)\n",
        "\n",
        "        # 将输出重排回 (batch, heads * 每个头的特征维度, time) 的形式\n",
        "        out = rearrange(out, \"b h c t -> b (h c) t\")\n",
        "\n",
        "        # 通过输出卷积层和GroupNorm，返回结果\n",
        "        return self.to_out(out)\n",
        "#輸入與輸出的形狀相同"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oC0IRKftlHVF"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn  # 接受一個子模塊，例如卷積或注意力層\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fn(x) + x  # 將輸入加到模塊的輸出上\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        # 使用GroupNorm替代LayerNorm，適合多維張量\n",
        "        self.norm = nn.GroupNorm(1, dim)  # 分成1組，相當於對每個通道獨立歸一化\n",
        "        self.fn = fn  # 接受一個子模塊\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fn(self.norm(x))  # 先對 x 進行層歸一化，再傳遞給子模塊\n",
        "\n",
        "class Downsample(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        # 使用卷积核大小为4，步长为2的卷积实现下采样\n",
        "        self.conv = nn.Conv1d(dim, dim, 4, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)  # 下采样特征图，宽度和高度减半\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        # 使用轉置卷積進行上采樣，將時間步長放大一倍\n",
        "        self.upsample = nn.ConvTranspose1d(dim, dim, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.upsample(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv2Bint-lHVF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from einops import rearrange\n",
        "\n",
        "# 定义U-Net网络结构，适用于时间序列数据\n",
        "class Unet(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            dim,  # 基本隐藏层维度\n",
        "            init_dim=None,  # 初始层维度，如果未提供则会根据dim计算得出\n",
        "            out_dim=None,  # 输出维度\n",
        "            dim_mults=(1, 2, 4, 8),  # 控制每个阶段隐藏层维度倍增的倍数\n",
        "            channels=1,  # 输入通道数，默认为1，适应时间序列数据\n",
        "            with_time_emb=True,  # 是否使用时间嵌入\n",
        "            resnet_block_groups=8,  # ResNet块中的组数\n",
        "            # use_convnext=False,  # 是否使用ConvNeXt块\n",
        "            # convnext_mult=2,  # ConvNeXt块的维度倍增因子\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # 初始层设置\n",
        "        self.channels = channels\n",
        "        init_dim = init_dim or dim // 3 * 2\n",
        "        self.init_conv = nn.Conv1d(channels, init_dim, 7, padding=3)  # 使用1D卷积\n",
        "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]  # 计算每层维度\n",
        "        # print(f'每層維度:{dims}')\n",
        "        in_out = list(zip(dims[:-1], dims[1:]))\n",
        "\n",
        "        block_klass = partial(ResnetBlock, groups=resnet_block_groups)\n",
        "\n",
        "        # 时间嵌入层\n",
        "        if with_time_emb:\n",
        "            time_dim = dim * 4\n",
        "            self.time_mlp = nn.Sequential(\n",
        "                nn.Linear(1, time_dim),  # 修改为线性时间嵌入，适用于1D数据\n",
        "                nn.GELU(),\n",
        "                nn.Linear(time_dim, time_dim),\n",
        "            )\n",
        "        else:\n",
        "            time_dim = None\n",
        "            self.time_mlp = None\n",
        "\n",
        "        # 下采样层\n",
        "        self.downs = nn.ModuleList([])\n",
        "        self.ups = nn.ModuleList([])\n",
        "        num_resolutions = len(in_out)  # 解析的层数\n",
        "        # 构建下采样模块 ,每層維度:[42, 64, 128, 256, 512]\n",
        "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
        "            # print((dim_in, dim_out))\n",
        "            is_last = ind >= (num_resolutions - 1)  # 是否为最后一层\n",
        "            self.downs.append(  # 添加下采样块\n",
        "                nn.ModuleList(\n",
        "                    [\n",
        "                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),  # 卷积块\n",
        "                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),  # 卷积块\n",
        "                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),  # 残差连接和注意力模块\n",
        "                        Downsample(dim_out) if not is_last else nn.Identity(),  # 下采样或恒等映射\n",
        "                    ]\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # 中间层\n",
        "        mid_dim = dims[-1]\n",
        "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
        "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))  # 使用多头注意力\n",
        "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
        "\n",
        "       # 构建上采样模块\n",
        "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
        "            is_last = ind >= (num_resolutions - 1)  # 是否是最后一次上采样，减2是因为我们需要留出一个输出层\n",
        "            self.ups.append(\n",
        "                nn.ModuleList(\n",
        "                    [\n",
        "                        # 卷积块，这里输入维度翻倍是因为上采样过程中会与编码器阶段的相应层进行拼接\n",
        "                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),\n",
        "                        # 卷积块\n",
        "                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),\n",
        "                        # 残差和注意力模块\n",
        "                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
        "                        # 上采样或恒等映射\n",
        "                        Upsample(dim_in) if not is_last else nn.Identity(),\n",
        "                    ]\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # 输出层\n",
        "        out_dim = out_dim or channels\n",
        "        self.final_conv = nn.Sequential(\n",
        "            nn.Conv1d(dim, dim, 3, padding=1),\n",
        "            nn.Conv1d(dim, out_dim, 1)  # 使用1D卷积输出最终结果\n",
        "        )\n",
        "\n",
        "    # 前向传播函数\n",
        "    def forward(self, x, time):\n",
        "        # 初始卷积层\n",
        "        x = self.init_conv(x)\n",
        "\n",
        "        # 如果有时间嵌入，进行时间编码\n",
        "        # print(f'time的大小{time.shape}')\n",
        "        t = self.time_mlp(time) if exists(self.time_mlp) else None\n",
        "\n",
        "        h = []  # 存储下采样时的特征\n",
        "        # 下采样过程\n",
        "        for block1, block2, attn, downsample in self.downs:\n",
        "            x = block1(x, t)  # 应用卷积块\n",
        "\n",
        "            x = block2(x, t)  # 应用卷积块\n",
        "\n",
        "            x = attn(x)  # 应用注意力模块\n",
        "\n",
        "            h.append(x)  # 存储特征图以便后续的拼接\n",
        "            x = downsample(x)  # 应用下采样或恒等映射\n",
        "            # print(x.shape)\n",
        "\n",
        "        # 中间层或瓶颈层\n",
        "        x = self.mid_block1(x, t)  # 第一个中间卷积块\n",
        "        x = self.mid_attn(x)  # 中间层的注意力模块\n",
        "        x = self.mid_block2(x, t)  # 第二个中间卷积块\n",
        "\n",
        "        # print(f'準備上採樣{x.shape}')\n",
        "        # 上采样过程\n",
        "        for block1, block2, attn, upsample in self.ups:\n",
        "            # 拼接特征图和对应的编码器阶段的特征图\n",
        "            x = torch.cat((x, h.pop()), dim=1)\n",
        "            x = block1(x, t)  # 应用卷积块\n",
        "            x = block2(x, t)  # 应用卷积块\n",
        "            x = attn(x)  # 应用注意力模块\n",
        "            x = upsample(x)  # 应用上采样或恒等映射\n",
        "\n",
        "        # 最后的输出层\n",
        "        return self.final_conv(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "topE8M4blHVH"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from diffusers import DDPMScheduler\n",
        "\n",
        "# # 初始化擴散調度器\n",
        "# num_train_timesteps = 1000\n",
        "# noise_scheduler = DDPMScheduler(num_train_timesteps=num_train_timesteps)\n",
        "\n",
        "# # 去噪過程\n",
        "# # ddim\n",
        "# def denoise(noisy_data, start_t, model, noise_scheduler):\n",
        "#     \"\"\"\n",
        "#     使用 DDIM 方法一步到位预测 x_0。\n",
        "\n",
        "#     Args:\n",
        "#         noisy_data (torch.Tensor): 噪声数据，形状为 (batch_size, features, seq_len)。\n",
        "#         start_t (int): 起始时间步。\n",
        "#         model (nn.Module): 噪声预测模型，输入为 (data, t)。\n",
        "#         noise_scheduler (DDPMScheduler): 噪声调度器，提供扩散参数。\n",
        "\n",
        "#     Returns:\n",
        "#         torch.Tensor: 直接预测的 x_0。\n",
        "#     \"\"\"\n",
        "#     #t = torch.randint(min_timesteps, max_timesteps, (batch_size,), device=device).long()\n",
        "#     # 生成当前时间步的张量\n",
        "#     t_tensor = start_t.unsqueeze(1).float()\n",
        "#     # t_tensor = torch.tensor([start_t], device=noisy_data.device).float().unsqueeze(1)\n",
        "#     # print(start_t.shape)\n",
        "#     # 预测噪声\n",
        "#     predicted_noise = model(noisy_data, t_tensor)\n",
        "#     # print(predicted_noise.shape)\n",
        "#     # print(noisy_data.shape)\n",
        "#     # 获取调度器参数\n",
        "#     alpha_bar_t = noise_scheduler.alphas_cumprod[start_t].view(-1, 1, 1)\n",
        "\n",
        "#     # alpha_bar_t = noise_scheduler.alphas_cumprod[start_t]\n",
        "#     # print(alpha_bar_t.shape)\n",
        "\n",
        "#     # 直接预测 x_0\n",
        "#     # x0_pred = (noisy_data - torch.sqrt(1 - alpha_bar_t) * predicted_noise) / torch.sqrt(alpha_bar_t)\n",
        "#     x0_pred = (noisy_data - torch.sqrt(torch.clamp(1 - alpha_bar_t, min=1e-5)) * predicted_noise) / torch.sqrt(alpha_bar_t)\n",
        "\n",
        "#     return x0_pred\n",
        "\n",
        "# # ddpm\n",
        "\n",
        "# # def denoise(noisy_data, start_t, model, noise_scheduler):\n",
        "\n",
        "# #     current_data = noisy_data\n",
        "# #     start_t = start_t.max().item()\n",
        "# #     for t in range(start_t, 0, -1):\n",
        "# #         # t_tensor = torch.tensor([t], device=current_data.device).float().unsqueeze(1)\n",
        "# #         # 預測噪聲\n",
        "# #         #print(current_data.shape)\n",
        "# #         # t = t.long()\n",
        "# #         predicted_noise = model(current_data, torch.tensor([t], device=current_data.device).float().unsqueeze(1))\n",
        "\n",
        "# #         # 計算去噪數據\n",
        "# #         alpha_t = noise_scheduler.alphas[t]\n",
        "# #         noise_scheduler.alphas_cumprod = noise_scheduler.alphas_cumprod.to(device)\n",
        "# #         alpha_bar_t = noise_scheduler.alphas_cumprod[t]\n",
        "# #         alpha_bar_t_prev = noise_scheduler.alphas_cumprod[t - 1] if t > 0 else 1.0\n",
        "# #         beta_t = 1 - alpha_t\n",
        "\n",
        "# #         mean = (1 / torch.sqrt(alpha_t)) * (current_data - beta_t / torch.sqrt(1 - alpha_bar_t) * predicted_noise)\n",
        "# #         if t > 0:\n",
        "# #             variance = torch.sqrt(beta_t * (1 - alpha_bar_t_prev) / (1 - alpha_bar_t))\n",
        "# #             current_data = mean + variance * torch.randn_like(current_data)\n",
        "# #         else:\n",
        "# #             current_data = mean\n",
        "# #     return current_data\n",
        "\n",
        "# from torch.amp import autocast\n",
        "\n",
        "\n",
        "# def diffusion_augmentation(data, noise_scheduler, model, t_min=799, t_max=900):\n",
        "#     device = data.device  # 確保所有張量在同一設備\n",
        "#     noise_scheduler.alphas_cumprod = noise_scheduler.alphas_cumprod.to(device)\n",
        "\n",
        "#     t = torch.randint(t_min, t_max, (data.size(0),), device=device)\n",
        "#     alpha_bar = noise_scheduler.alphas_cumprod[t].view(-1, 1, 1)\n",
        "#     noise = torch.randn_like(data, device=device)\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         with autocast(device_type=\"cuda\", dtype=torch.float16):  # 新語法，指定設備\n",
        "#             noisy_data = torch.sqrt(alpha_bar) * data + torch.sqrt(1 - alpha_bar) * noise\n",
        "#             augmented_data = denoise(noisy_data,\n",
        "#                                      t# t.max().item()\n",
        "#                                      , model.to(device), noise_scheduler)\n",
        "\n",
        "#     return augmented_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_d-m0pT1dVh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import DDPMScheduler\n",
        "\n",
        "# 初始化擴散調度器\n",
        "num_train_timesteps = 1000\n",
        "noise_scheduler = DDPMScheduler(num_train_timesteps=num_train_timesteps)\n",
        "\n",
        "# 去噪過程\n",
        "# ddim\n",
        "\n",
        "\n",
        "# ddpm\n",
        "\n",
        "import torch\n",
        "\n",
        "def denoise(noisy_data, start_t, model, noise_scheduler, step_size=100):\n",
        "    device = noisy_data.device  # 确保所有张量在同一设备上\n",
        "    current_data = noisy_data\n",
        "    model = model.to(device)  # 确保模型在正确的设备上\n",
        "    noise_scheduler.alphas_cumprod = noise_scheduler.alphas_cumprod.to(device)  # 确保 alphas_cumprod 在正确的设备上\n",
        "\n",
        "    for t in range(start_t.max(), 0, -step_size):\n",
        "        t_tensor = torch.tensor([t], device=device, dtype=torch.float32).unsqueeze(1)\n",
        "        predicted_noise = model(current_data, t_tensor)\n",
        "\n",
        "        alpha_t = noise_scheduler.alphas[t]\n",
        "        alpha_bar_t = noise_scheduler.alphas_cumprod[t]\n",
        "        alpha_bar_t_prev = noise_scheduler.alphas_cumprod[t - step_size] if t - step_size > 0 else 1.0\n",
        "        beta_t = 1 - alpha_t\n",
        "\n",
        "        mean = (1 / torch.sqrt(alpha_t)) * (current_data - beta_t / torch.sqrt(1 - alpha_bar_t) * predicted_noise)\n",
        "        if t > step_size:\n",
        "            variance = torch.sqrt(beta_t * (1 - alpha_bar_t_prev) / (1 - alpha_bar_t))\n",
        "            current_data = mean + variance * torch.randn_like(current_data)\n",
        "        else:\n",
        "            current_data = mean\n",
        "\n",
        "    return current_data\n",
        "\n",
        "\n",
        "from torch.amp import autocast\n",
        "\n",
        "\n",
        "def diffusion_augmentation(data, noise_scheduler, model, fixed_t=700):\n",
        "    device = data.device\n",
        "    # print(f'input_shape:{data.shape}')  # 确保所有张量在同一设备\n",
        "    noise_scheduler.alphas_cumprod = noise_scheduler.alphas_cumprod.to(device)\n",
        "\n",
        "    t = torch.full((data.size(0),), fixed_t, device=device, dtype=torch.long)  # 固定时间步为 700\n",
        "    alpha_bar = noise_scheduler.alphas_cumprod[t].view(-1, 1, 1)\n",
        "    noise = torch.randn_like(data, device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        with autocast(device_type=\"cuda\", dtype=torch.float16):  # 使用 autocast 进行混合精度计算\n",
        "            noisy_data = torch.sqrt(alpha_bar) * data + torch.sqrt(1 - alpha_bar) * noise\n",
        "            augmented_data = denoise(noisy_data, t, model.to(device), noise_scheduler)\n",
        "    # print(f'output_shape:{augmented_data.shape}')\n",
        "    return augmented_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNYCp1AG-_Zy"
      },
      "source": [
        "##傳統的augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99ljnKpW_D0K"
      },
      "outputs": [],
      "source": [
        "class TimeSeriesAugmentor:\n",
        "    def __init__(self, jitter_sigma=0.01, scaling_sigma=0.1, mask_ratio=0.1):\n",
        "        self.jitter_sigma = jitter_sigma\n",
        "        self.scaling_sigma = scaling_sigma\n",
        "        self.mask_ratio = mask_ratio\n",
        "\n",
        "    def jitter(self, X):\n",
        "        noise = np.random.normal(loc=0, scale=self.jitter_sigma, size=X.shape)\n",
        "        return X + noise\n",
        "\n",
        "    def scaling(self, X):\n",
        "        scaling_factor = np.random.normal(loc=1.0, scale=self.scaling_sigma, size=(X.shape[0], X.shape[1], 1))\n",
        "        return X * scaling_factor\n",
        "\n",
        "    def masking(self, X):\n",
        "        X_masked = X.clone()\n",
        "        batch_size, num_features, seq_len = X.shape\n",
        "        num_mask = int(seq_len * self.mask_ratio)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            mask_idx = np.random.choice(seq_len, num_mask, replace=False)\n",
        "            X_masked[i, :, mask_idx] = 0  # 可以改成 np.nan 視你的模型處理方式而定\n",
        "\n",
        "        return X_masked\n",
        "\n",
        "    def generate_views(self, X):\n",
        "        \"\"\"\n",
        "        輸入 X: shape = (batch_size, features, time)\n",
        "        回傳 view1, view2\n",
        "        \"\"\"\n",
        "        view1 = self.jitter(X)\n",
        "        view2 = self.scaling(X)\n",
        "        view2 = self.masking(view2)\n",
        "        return view1, view2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3DZ2d6HiZ2u"
      },
      "source": [
        "##在使用diff_model訓練時再加就好"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiJl6KoaOs-1"
      },
      "outputs": [],
      "source": [
        "# model = Unet(\n",
        "#     dim=64,            # 基礎隱藏層維度\n",
        "#     channels=31,        # 輸入通道數，適合單通道時序數據\n",
        "#     dim_mults=(1, 2, 4, 8),  # 各層維度倍增\n",
        "#     with_time_emb=True,  # 使用時間嵌入\n",
        "\n",
        "# ).to('cpu')\n",
        "# model = torch.load(\"/content/model_with_structure.pth\", weights_only=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhrKg_9RlHVH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, embed_dim, num_heads, num_layers, dropout=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.input_dim = input_dim  # 特徵數量\n",
        "        self.embed_dim = embed_dim  # Transformer 的嵌入維度\n",
        "\n",
        "        # 將輸入特徵嵌入到 Transformer 的維度\n",
        "        self.feature_embedding = nn.Linear(input_dim, embed_dim)\n",
        "\n",
        "        # 位置編碼\n",
        "        self.positional_encoding = nn.Parameter(torch.zeros(1, 32, embed_dim))  # 時間長度固定為 32\n",
        "\n",
        "        # Transformer 編碼器\n",
        "        encoder_layer = nn.TransformerEncoderLayer(embed_dim, num_heads, dim_feedforward=embed_dim * 4, dropout=dropout)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: [batch_size, 特徵, 時間] -> [batch_size, input_dim, seq_len]\n",
        "        Returns:\n",
        "            encoded: [batch_size, embed_dim] - 編碼後的特徵\n",
        "        \"\"\"\n",
        "        # 調整輸入形狀\n",
        "        x = x.permute(0, 2, 1)  # [batch_size, 特徵, 時間] -> [batch_size, 時間, 特徵]\n",
        "        x = self.feature_embedding(x)  # [batch_size, 時間, 特徵] -> [batch_size, 時間, embed_dim]\n",
        "\n",
        "        # 添加位置編碼\n",
        "        x = x + self.positional_encoding\n",
        "\n",
        "        # 應用 Transformer\n",
        "        encoded = self.transformer(x)  # [batch_size, 時間, embed_dim]\n",
        "        return encoded[:, 0, :]  # 取 CLS 標籤作為全局特徵\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJ9zmKCfC9g4"
      },
      "outputs": [],
      "source": [
        "class SimSiamForTimeSeries(nn.Module):\n",
        "    def __init__(self, input_dim, embed_dim=128, projector_dim=256, predictor_dim=128, num_heads=4, num_layers=2):\n",
        "        super(SimSiamForTimeSeries, self).__init__()\n",
        "        self.encoder = TransformerEncoder(input_dim, embed_dim, num_heads, num_layers)\n",
        "\n",
        "        # Projector: MLP\n",
        "        self.projector = nn.Sequential(\n",
        "            nn.Linear(embed_dim, projector_dim),\n",
        "            nn.BatchNorm1d(projector_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(projector_dim, projector_dim)\n",
        "        )\n",
        "\n",
        "        # Predictor: MLP\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.Linear(projector_dim, predictor_dim),\n",
        "            nn.BatchNorm1d(predictor_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(predictor_dim, projector_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        z1 = self.projector(self.encoder(x1))  # View 1\n",
        "        z2 = self.projector(self.encoder(x2))  # View 2\n",
        "        p1 = self.predictor(z1)\n",
        "        p2 = self.predictor(z2)\n",
        "        return p1, z1.detach(), p2, z2.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I89rawOsVq01"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx3RSygflHVH"
      },
      "outputs": [],
      "source": [
        "def simsiam_loss(p1, z2, p2, z1, verbose=False):\n",
        "    def negative_cosine_similarity(p, z):\n",
        "        p = torch.nn.functional.normalize(p, dim=1, eps=1e-6)\n",
        "        z = torch.nn.functional.normalize(z, dim=1, eps=1e-6)\n",
        "        return -torch.mean(torch.sum(p * z, dim=1))\n",
        "\n",
        "    loss1 = negative_cosine_similarity(p1, z2)\n",
        "    loss2 = negative_cosine_similarity(p2, z1)\n",
        "    if verbose:\n",
        "        print(f\"loss1: {loss1.item():.4f}, loss2: {loss2.item():.4f}\")\n",
        "    return (loss1 + loss2) / 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOGYthU-9Sm3"
      },
      "source": [
        "##diff_augment的訓練函數"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRAsN-UVqDMn"
      },
      "outputs": [],
      "source": [
        "def validate(model, simsiam_model, noise_scheduler, val_loader, device):\n",
        "    \"\"\"\n",
        "    使用 DataLoader 驗證 SimSiam 模型。\n",
        "\n",
        "    Args:\n",
        "        model: 擴散模型，用於生成增強數據。\n",
        "        simsiam_model: SimSiam 模型。\n",
        "        noise_scheduler: 噪聲調度器 (DDPMScheduler)。\n",
        "        val_loader: 驗證數據的 DataLoader。\n",
        "        device: 設備 (CPU/GPU)。\n",
        "    Returns:\n",
        "        avg_val_loss: 驗證集的平均損失。\n",
        "    \"\"\"\n",
        "    simsiam_model.eval()  # 設置為驗證模式\n",
        "    total_val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():  # 不計算梯度\n",
        "        with tqdm(val_loader, desc=\"Validation\", unit=\"batch\") as val_pbar:\n",
        "            for batch in val_pbar:\n",
        "                batch = batch.to(device).float()  # ✅ 放到 GPU\n",
        "\n",
        "                # batch = batch.to(torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "                # 數據增強\n",
        "                view1 = diffusion_augmentation(batch, noise_scheduler, model)\n",
        "                view2 = diffusion_augmentation(batch, noise_scheduler, model)\n",
        "\n",
        "                # SimSiam 前向傳播\n",
        "                p1, z1, p2, z2 = simsiam_model(view1, view2)\n",
        "\n",
        "                # 計算損失\n",
        "                loss = simsiam_loss(p1, z2, p2, z1)\n",
        "                total_val_loss += loss.item()\n",
        "\n",
        "                # 更新進度條\n",
        "                val_pbar.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    return avg_val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3gPldVF7SyB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def load_checkpoint(model, optimizer, filepath=\"checkpoint.pth\"):\n",
        "    if os.path.exists(filepath):\n",
        "        checkpoint = torch.load(filepath, map_location=torch.device(\"cpu\"))\n",
        "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "        start_epoch = checkpoint[\"epoch\"] + 1\n",
        "        print(f\"Checkpoint loaded from {filepath}, starting at epoch {start_epoch}\")\n",
        "        return start_epoch\n",
        "    else:\n",
        "        print(f\"No checkpoint found at {filepath}, starting from scratch\")\n",
        "        return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FC3-a8_U7WaV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, simsiam_model, noise_scheduler, optimizer, train_dataloader, val_dataloader, epochs, device, resume_from_checkpoint=None):\n",
        "    model = model.to(device)\n",
        "    simsiam_model = simsiam_model.to(device)\n",
        "    noise_scheduler.alphas_cumprod = noise_scheduler.alphas_cumprod.to(device)\n",
        "\n",
        "    results = []  # 记录每个 epoch 的结果\n",
        "    start_epoch = 0\n",
        "\n",
        "    # 加载检查点\n",
        "    if resume_from_checkpoint:\n",
        "        checkpoint = torch.load(resume_from_checkpoint, map_location=device)\n",
        "        simsiam_model.load_state_dict(checkpoint[\"simsiam_model_state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "        start_epoch = checkpoint[\"epoch\"] + 1\n",
        "        print(f\"已加载检查点: {resume_from_checkpoint}, 从第 {start_epoch} 个 epoch 开始\")\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        simsiam_model.train()\n",
        "        epoch_train_loss = 0.0\n",
        "\n",
        "        # 训练循环\n",
        "        with tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as train_pbar:\n",
        "            for batch in train_pbar:\n",
        "                batch = batch.to(device).float()  # ✅ 放到 GPU\n",
        "\n",
        "                # batch = batch.to(torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "                # 检查数据是否有 NaN 或 Inf\n",
        "                if torch.isnan(batch).any() or torch.isinf(batch).any():\n",
        "                    print(\"Batch contains NaN or Inf. Skipping this batch.\")\n",
        "                    continue\n",
        "\n",
        "                # 数据增强(view裡面包含nan)\n",
        "                view1 = diffusion_augmentation(batch, noise_scheduler, model)\n",
        "                view2 = diffusion_augmentation(batch, noise_scheduler, model)\n",
        "\n",
        "                # 检查增强视图是否有 NaN 或 Inf\n",
        "                if torch.isnan(view1).any() or torch.isinf(view1).any():\n",
        "                    print(\"view1 contains NaN or Inf. Skipping this batch.\")\n",
        "                    continue\n",
        "                if torch.isnan(view2).any() or torch.isinf(view2).any():\n",
        "                    print(\"view2 contains NaN or Inf. Skipping this batch.\")\n",
        "                    continue\n",
        "\n",
        "                # SimSiam 前向传播\n",
        "                p1, z1, p2, z2 = simsiam_model(view1, view2)\n",
        "\n",
        "                # 检查模型输出是否有 NaN 或 Inf\n",
        "                # for name, tensor in {\"p1\": p1, \"z1\": z1, \"p2\": p2, \"z2\": z2}.items():\n",
        "                #     if torch.isnan(tensor).any() or torch.isinf(tensor).any():\n",
        "                #         print(f\"{name} contains NaN or Inf. Skipping this batch.\")\n",
        "                #         continue\n",
        "\n",
        "                # 计算损失\n",
        "                loss = simsiam_loss(p1, z2, p2, z1)\n",
        "                # print(f\"loss = {loss.item()}\")\n",
        "\n",
        "                # 检查损失是否为 NaN 或 Inf\n",
        "                # print(f\"loss = {loss.item()}\")\n",
        "                # continue\n",
        "                # if torch.isnan(loss).any() or torch.isinf(loss).any():\n",
        "                #     print(\"Loss contains NaN or Inf. Skipping this batch.\")\n",
        "                #     continue\n",
        "\n",
        "                # 反向传播和优化\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "\n",
        "                # 梯度裁剪\n",
        "                torch.nn.utils.clip_grad_norm_(simsiam_model.parameters(), max_norm=1.0)\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_train_loss += loss.item()\n",
        "                train_pbar.set_postfix(loss=loss.item())\n",
        "\n",
        "        # 计算训练和验证损失\n",
        "        avg_train_loss = epoch_train_loss / len(train_dataloader)\n",
        "        avg_val_loss = validate(model, simsiam_model, noise_scheduler, val_dataloader, device)\n",
        "\n",
        "        results.append({\"epoch\": epoch + 1, \"train_loss\": avg_train_loss, \"val_loss\": avg_val_loss})\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}: Train Loss = {avg_train_loss:.4f}, Validation Loss = {avg_val_loss:.4f}\")\n",
        "\n",
        "        # 保存检查点\n",
        "        now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"+'ddpm_700')\n",
        "        save_path = f\"checkpoint_epoch_{epoch+1}_{now}.pt\"\n",
        "        torch.save({\n",
        "            \"simsiam_model_state_dict\": simsiam_model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"epoch\": epoch,\n",
        "        }, save_path)\n",
        "        tqdm.write(f\"Checkpoint saved at {save_path}\")\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FdGFLPf9Zzo"
      },
      "source": [
        "##傳統augment_的訓練函數"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "zFPgz1mS2Zsr",
        "outputId": "a3116b97-f701-4cf9-cdba-f5cd25d21633"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'clone'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-ce14265c25c3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 生成 view1（jittering）與 view2（scaling + masking）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mview1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugmentor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_views\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 顯示測試結果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d6370108ea08>\u001b[0m in \u001b[0;36mgenerate_views\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mview1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mview2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mview2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mview2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mview1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d6370108ea08>\u001b[0m in \u001b[0;36mmasking\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmasking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mX_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mnum_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'clone'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 建立假資料 X: shape = (4, 31, 32)\n",
        "np.random.seed(42)  # 為了可重現\n",
        "X = np.random.rand(4, 31, 32)  # 假設股價因子數值都在 0~1\n",
        "\n",
        "# 初始化增強器\n",
        "augmentor = TimeSeriesAugmentor(jitter_sigma=0.02, scaling_sigma=0.15, mask_ratio=0.2)\n",
        "\n",
        "# 生成 view1（jittering）與 view2（scaling + masking）\n",
        "view1, view2 = augmentor.generate_views(X)\n",
        "\n",
        "# 顯示測試結果\n",
        "print(\"Original X[0][0][:5]:\\n\", X[0][0][:5])\n",
        "print(\"View1 (Jittered) X[0][0][:5]:\\n\", view1.shape)\n",
        "print(\"View2 (Scaled + Masked) X[0][0][:5]:\\n\", view2.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEdlTBHY9i9H"
      },
      "outputs": [],
      "source": [
        "def validate(augmentor,simsiam_model, val_loader, device):\n",
        "    \"\"\"\n",
        "    使用 DataLoader 驗證 SimSiam 模型。\n",
        "\n",
        "    Args:\n",
        "        model: 擴散模型，用於生成增強數據。\n",
        "        simsiam_model: SimSiam 模型。\n",
        "        noise_scheduler: 噪聲調度器 (DDPMScheduler)。\n",
        "        val_loader: 驗證數據的 DataLoader。\n",
        "        device: 設備 (CPU/GPU)。\n",
        "    Returns:\n",
        "        avg_val_loss: 驗證集的平均損失。\n",
        "    \"\"\"\n",
        "    simsiam_model.eval()  # 設置為驗證模式\n",
        "    total_val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():  # 不計算梯度\n",
        "        with tqdm(val_loader, desc=\"Validation\", unit=\"batch\") as val_pbar:\n",
        "            for batch in val_pbar:\n",
        "                batch = batch.to(device).float()  # ✅ 放到 GPU\n",
        "\n",
        "                # batch = batch.to(torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "                # 數據增強\n",
        "                view1, view2 = augmentor.generate_views(batch)\n",
        "                view1 = view1.float()\n",
        "                view2 = view2.float()\n",
        "\n",
        "                # SimSiam 前向傳播\n",
        "                p1, z1, p2, z2 = simsiam_model(view1, view2)\n",
        "\n",
        "                # 計算損失\n",
        "                loss = simsiam_loss(p1, z2, p2, z1)\n",
        "                total_val_loss += loss.item()\n",
        "\n",
        "                # 更新進度條\n",
        "                val_pbar.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    return avg_val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAaDHEnb-Zoz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def load_checkpoint(model, optimizer, filepath=\"checkpoint.pth\"):\n",
        "    if os.path.exists(filepath):\n",
        "        checkpoint = torch.load(filepath, map_location=torch.device(\"cpu\"))\n",
        "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "        start_epoch = checkpoint[\"epoch\"] + 1\n",
        "        print(f\"Checkpoint loaded from {filepath}, starting at epoch {start_epoch}\")\n",
        "        return start_epoch\n",
        "    else:\n",
        "        print(f\"No checkpoint found at {filepath}, starting from scratch\")\n",
        "        return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GksXc-TO-orR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_tran(augmentor, simsiam_model, optimizer, train_dataloader, val_dataloader, epochs, device, resume_from_checkpoint=None):\n",
        "\n",
        "    simsiam_model = simsiam_model.to(device)\n",
        "\n",
        "    results = []  # 记录每个 epoch 的结果\n",
        "    start_epoch = 0\n",
        "\n",
        "    # 加载检查点\n",
        "    if resume_from_checkpoint:\n",
        "        checkpoint = torch.load(resume_from_checkpoint, map_location=device)\n",
        "        simsiam_model.load_state_dict(checkpoint[\"simsiam_model_state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "        start_epoch = checkpoint[\"epoch\"] + 1\n",
        "        print(f\"已加载检查点: {resume_from_checkpoint}, 从第 {start_epoch} 个 epoch 开始\")\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        simsiam_model.train()\n",
        "        epoch_train_loss = 0.0\n",
        "\n",
        "        # 训练循环\n",
        "        with tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as train_pbar:\n",
        "            for batch in train_pbar:\n",
        "                batch = batch.to(device).float()  # ✅ 放到 GPU\n",
        "\n",
        "                # batch = batch.to(torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "                # 检查数据是否有 NaN 或 Inf\n",
        "                if torch.isnan(batch).any() or torch.isinf(batch).any():\n",
        "                    print(\"Batch contains NaN or Inf. Skipping this batch.\")\n",
        "                    continue\n",
        "\n",
        "                # 数据增强(view裡面包含nan)\n",
        "                view1, view2 = augmentor.generate_views(batch)\n",
        "                view1 = view1.float()\n",
        "                view2 = view2.float()\n",
        "\n",
        "\n",
        "                # 检查增强视图是否有 NaN 或 Inf\n",
        "                if torch.isnan(view1).any() or torch.isinf(view1).any():\n",
        "                    print(\"view1 contains NaN or Inf. Skipping this batch.\")\n",
        "                    continue\n",
        "                if torch.isnan(view2).any() or torch.isinf(view2).any():\n",
        "                    print(\"view2 contains NaN or Inf. Skipping this batch.\")\n",
        "                    continue\n",
        "\n",
        "                # SimSiam 前向传播\n",
        "                p1, z1, p2, z2 = simsiam_model(view1, view2)\n",
        "                loss = simsiam_loss(p1, z2, p2, z1)\n",
        "\n",
        "                # 反向传播和优化\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "\n",
        "                # 梯度裁剪\n",
        "                torch.nn.utils.clip_grad_norm_(simsiam_model.parameters(), max_norm=1.0)\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_train_loss += loss.item()\n",
        "                train_pbar.set_postfix(loss=loss.item())\n",
        "\n",
        "        # 计算训练和验证损失\n",
        "        avg_train_loss = epoch_train_loss / len(train_dataloader)\n",
        "        avg_val_loss = validate(augmentor, simsiam_model, val_dataloader, device)\n",
        "\n",
        "        results.append({\"epoch\": epoch + 1, \"train_loss\": avg_train_loss, \"val_loss\": avg_val_loss})\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}: Train Loss = {avg_train_loss:.4f}, Validation Loss = {avg_val_loss:.4f}\")\n",
        "\n",
        "        # 保存检查点\n",
        "        now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"+'tran_augment')\n",
        "        save_path = f\"checkpoint_epoch_{epoch+1}_{now}.pt\"\n",
        "        torch.save({\n",
        "            \"simsiam_model_state_dict\": simsiam_model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"epoch\": epoch,\n",
        "        }, save_path)\n",
        "        tqdm.write(f\"Checkpoint saved at {save_path}\")\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2jmiCJv_v88"
      },
      "source": [
        "##load對比學習訓練資料"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgOCHffuUxhT"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# # # 數據集分割\n",
        "# # train_size = int(0.8 * len(dataset))\n",
        "# # val_size = len(dataset) - train_size\n",
        "# # train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "# # np.save(\"train_data.npy\", train_dataset)\n",
        "# # np.save('val_data.npy',val_dataset)\n",
        "\n",
        "# # 加載數據\n",
        "# train_dataset = np.load('/content/X_train_norm.npy')\n",
        "# val_dataset = np.load('/content/X_val_norm.npy')\n",
        "\n",
        "# # 創建 DataLoader\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "# val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecW9bZP8xj76",
        "outputId": "7f880e82-1e3a-4dbd-ab0e-242d68fe2325"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train.shape = (92583, 32, 31)\n",
            "y_train.shape = (92583,)\n",
            "X_test.shape  = (21717, 32, 31)\n",
            "y_test.shape  = (21717,)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "# 讀取時\n",
        "data = np.load('/content/dataset_LSTM_binary.npz')\n",
        "data\n",
        "X_train = data['X_train']\n",
        "y_train = data['y_train']\n",
        "X_test  = data['X_test']\n",
        "y_test  = data['y_test']\n",
        "print('X_train.shape =', X_train.shape)  # (samples_train, time_steps, features)\n",
        "print('y_train.shape =', y_train.shape)  # (samples_train,)\n",
        "print('X_test.shape  =', X_test.shape)   # (samples_test, time_steps, features)\n",
        "print('y_test.shape  =', y_test.shape)   # (samples_test,)\n",
        "\n",
        "# t_mean = X_train.mean(axis=(0, 2), keepdims=True)  # shape: (1, features, 1)\n",
        "# t_std = X_train.std(axis=(0, 2), keepdims=True)    # shape: (1, features, 1)\n",
        "# v_mean = X_train.mean(axis=(0, 2), keepdims=True)  # shape: (1, features, 1)\n",
        "# v_std = X_train.std(axis=(0, 2), keepdims=True)    # shape: (1, features, 1)\n",
        "# # 正規化\n",
        "# X_train_norm = (X_train - t_mean) / (t_std + 1e-8)\n",
        "# X_val_norm = (X_test - v_mean) / (v_std + 1e-8)\n",
        "# 將 NumPy 陣列轉成 PyTorch tensor (float32)\n",
        "train_dataset = torch.from_numpy(X_train.astype(np.float32)).permute(0, 2, 1)\n",
        "val_dataset = torch.from_numpy(X_test.astype(np.float32)).permute(0, 2, 1)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lfhY8qgsXDs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "train_dataset = np.load('/content/train_data.npy')\n",
        "val_dataset = np.load('/content/val_data.npy')\n",
        "t_mean = train_dataset.mean(axis=(0, 2), keepdims=True)  # shape: (1, features, 1)\n",
        "t_std = train_dataset.std(axis=(0, 2), keepdims=True)    # shape: (1, features, 1)\n",
        "v_mean = train_dataset.mean(axis=(0, 2), keepdims=True)  # shape: (1, features, 1)\n",
        "v_std = train_dataset.std(axis=(0, 2), keepdims=True)    # shape: (1, features, 1)\n",
        "# 正規化\n",
        "X_train_norm = (train_dataset - t_mean) / (t_std + 1e-8)\n",
        "X_val_norm = (val_dataset - v_mean) / (v_std + 1e-8)\n",
        "\n",
        "np.save(\"X_train_norm.npy\", X_train_norm)\n",
        "np.save('X_val_norm.npy',X_val_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "3PMHLRiw_y0s",
        "outputId": "ee7215fc-5887-44ef-d3a2-d7893e0bf5b1"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_tran' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-c4462a0cf118>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msimsiam_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimSiamForTimeSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimsiam_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m results = train_tran(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0maugmentor\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msimsiam_model\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_tran' is not defined"
          ]
        }
      ],
      "source": [
        "device = 'cpu'#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_dim = 31  # 特徵數\n",
        "augmentor = TimeSeriesAugmentor(jitter_sigma=0.02, scaling_sigma=0.15, mask_ratio=0.2)\n",
        "simsiam_model = SimSiamForTimeSeries(input_dim).to(device)\n",
        "optimizer = torch.optim.Adam(simsiam_model.parameters(), lr=1e-5)\n",
        "results = train_tran(\n",
        "    augmentor ,\n",
        "    simsiam_model ,\n",
        "    optimizer,\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    epochs =20,\n",
        "    device = device,\n",
        "    resume_from_checkpoint = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYvF-0XtUHOj",
        "outputId": "4540e9f7-7a53-4e85-967f-deb30622d376"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "已加载检查点: /content/checkpoint_epoch_4_2025-04-21_07-45-24ddpm_400-700.pt, 从第 4 个 epoch 开始\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20:   0%|          | 0/724 [00:00<?, ?batch/s]/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "Epoch 5/20: 100%|██████████| 724/724 [1:52:32<00:00,  9.33s/batch, loss=-0.944]\n",
            "Validation: 100%|██████████| 170/170 [24:19<00:00,  8.59s/batch, loss=-0.965]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/20: Train Loss = -0.9404, Validation Loss = -0.9542\n",
            "Checkpoint saved at checkpoint_epoch_5_2025-04-29_15-20-10ddpm_300.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20: 100%|██████████| 724/724 [1:51:42<00:00,  9.26s/batch, loss=-0.941]\n",
            "Validation: 100%|██████████| 170/170 [24:08<00:00,  8.52s/batch, loss=-0.973]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/20: Train Loss = -0.9516, Validation Loss = -0.9674\n",
            "Checkpoint saved at checkpoint_epoch_6_2025-04-29_17-36-01ddpm_300.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20: 100%|██████████| 724/724 [1:51:15<00:00,  9.22s/batch, loss=-0.956]\n",
            "Validation: 100%|██████████| 170/170 [23:58<00:00,  8.46s/batch, loss=-0.975]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/20: Train Loss = -0.9592, Validation Loss = -0.9691\n",
            "Checkpoint saved at checkpoint_epoch_7_2025-04-29_19-51-14ddpm_300.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/20:  11%|█         | 79/724 [12:03<1:40:14,  9.33s/batch, loss=-0.969]"
          ]
        }
      ],
      "source": [
        "#-0.8137, Validation Loss = -0.8974\n",
        "noise_scheduler = DDPMScheduler(num_train_timesteps = 1000)\n",
        "device = 'cpu'#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_dim = 31  # 特徵數\n",
        "simsiam_model = SimSiamForTimeSeries(input_dim).to(device)\n",
        "optimizer = torch.optim.Adam(simsiam_model.parameters(), lr=1e-5)\n",
        "results = train(\n",
        "    model,\n",
        "    simsiam_model ,\n",
        "    noise_scheduler,\n",
        "    optimizer,\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    epochs =20,\n",
        "    device = device,\n",
        "    resume_from_checkpoint = '/content/checkpoint_epoch_4_2025-04-21_07-45-24ddpm_400-700.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV59vC9hkQKE"
      },
      "source": [
        "##預測訓練資料"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39zLR8ELQwY9",
        "outputId": "64c48061-833a-4f74-f24f-d2995e9cc9c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train.shape = (92583, 32, 31)\n",
            "y_train.shape = (92583,)\n",
            "X_test.shape  = (21717, 32, 31)\n",
            "y_test.shape  = (21717,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# 讀取時\n",
        "data = np.load('dataset_LSTM.npz')\n",
        "X_train = data['X_train']\n",
        "y_train = data['y_train']\n",
        "X_test  = data['X_test']\n",
        "y_test  = data['y_test']\n",
        "\n",
        "print('X_train.shape =', X_train.shape)  # (samples_train, time_steps, features)\n",
        "print('y_train.shape =', y_train.shape)  # (samples_train,)\n",
        "print('X_test.shape  =', X_test.shape)   # (samples_test, time_steps, features)\n",
        "print('y_test.shape  =', y_test.shape)   # (samples_test,)\n",
        "\n",
        "t_mean = X_train.mean(axis=(0, 2), keepdims=True)  # shape: (1, features, 1)\n",
        "t_std = X_train.std(axis=(0, 2), keepdims=True)    # shape: (1, features, 1)\n",
        "v_mean = X_train.mean(axis=(0, 2), keepdims=True)  # shape: (1, features, 1)\n",
        "v_std = X_train.std(axis=(0, 2), keepdims=True)    # shape: (1, features, 1)\n",
        "# 正規化\n",
        "X_train_norm = (X_train - t_mean) / (t_std + 1e-8)\n",
        "X_val_norm = (y_test - v_mean) / (v_std + 1e-8)\n",
        "\n",
        "# np.save(\"X_train_norm.npy\", X_train_norm)\n",
        "# np.save('X_val_norm.npy',X_val_norm)\n",
        "# 將 NumPy 陣列轉成 PyTorch tensor (float32)\n",
        "X_train_t = torch.from_numpy(X_train_norm.astype(np.float32))\n",
        "y_train_t = torch.from_numpy(y_train.astype(np.float32))\n",
        "\n",
        "X_test_t  = torch.from_numpy(X_val_norm.astype(np.float32))\n",
        "y_test_t  = torch.from_numpy(y_test.astype(np.float32))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbNTpqzW_0q6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hT1ievDCHrW6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class EmbeddingPredictor(nn.Module):\n",
        "    def __init__(self, encoder, embedding_dim=128, hidden_dims=None, out_dim=1):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "\n",
        "        if hidden_dims is None:\n",
        "            hidden_dims = [64]\n",
        "\n",
        "        layers = []\n",
        "        prev_dim = embedding_dim\n",
        "        for hd in hidden_dims:\n",
        "            layers.append(nn.Linear(prev_dim, hd))\n",
        "            layers.append(nn.ReLU())\n",
        "            prev_dim = hd\n",
        "\n",
        "        layers.append(nn.Linear(prev_dim, out_dim))\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            embedding = self.encoder(x.permute(0,2,1))  # => [B, embedding_dim]\n",
        "        out = self.mlp(embedding)        # => [B, out_dim]\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDtW_e5_HWOt"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()  # 啟用 train 模式\n",
        "    total_loss = 0.0\n",
        "\n",
        "    pbar = tqdm(loader, desc=\"Train\", leave=False)\n",
        "    for batch_x, batch_y in pbar:\n",
        "        batch_x = batch_x.to(device)\n",
        "\n",
        "        batch_y = batch_y.to(device).float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = model(batch_x).squeeze(-1)  # => [B]\n",
        "        if batch_y.dim() == 2:\n",
        "            batch_y = batch_y.squeeze(-1)\n",
        "\n",
        "        loss = criterion(y_pred, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        pbar.set_postfix({\"batch_loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    return avg_loss\n",
        "def eval_one_epoch(model, loader, criterion, device, desc=\"Eval\"):\n",
        "    \"\"\"\n",
        "    通用的 \"驗證/測試\" 函式:\n",
        "      - model.eval()\n",
        "      - 不做反向傳播\n",
        "      - 只計算平均損失 (回歸可用 MSELoss)\n",
        "\n",
        "    desc: \"Valid\" or \"Test\" 或其他字串，給 tqdm 用\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    pbar = tqdm(loader, desc=desc, leave=False)\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in pbar:\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device).float()\n",
        "\n",
        "            y_pred = model(batch_x).squeeze(-1)\n",
        "            if batch_y.dim() == 2:\n",
        "                batch_y = batch_y.squeeze(-1)\n",
        "\n",
        "            loss = criterion(y_pred, batch_y)\n",
        "            total_loss += loss.item()\n",
        "            pbar.set_postfix({\"batch_loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    return avg_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9KFwJeZvLud"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "test_dataset  = TensorDataset(X_test_t,  y_test_t)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdXjscl6tD1V"
      },
      "outputs": [],
      "source": [
        "device = 'cpu'#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_dim = 31  # 特徵數\n",
        "simsiam_model = SimSiamForTimeSeries(input_dim).to(device)\n",
        "checkpoint = torch.load('/content/checkpoint_epoch_9_2025-04-25_14-35-03tran_augment.pt', map_location=device)\n",
        "simsiam_model.load_state_dict(checkpoint[\"simsiam_model_state_dict\"])\n",
        "encoder = simsiam_model.encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "iVVVZzslHjCw",
        "outputId": "098c6071-f70a-4d01-fafd-3ad23532b6ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss = 10.7562, Val Loss = 10.7374\n",
            "  (New best model saved!)\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-8986f711e5fd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# 1) train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# 2) validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-078a087f2288>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# => [B]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-ac6693253131>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# => [B, embedding_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# => [B, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# => [B, 1] between 0 and 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-12117b35e7ce>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# 應用 Transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch_size, 時間, embed_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 取 CLS 標籤作為全局特徵\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             output = mod(\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             )\n\u001b[0;32m--> 922\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_ff_block\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dropout probability has to be between 0 and 1, but got {p}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m     return (\n\u001b[0;32m-> 1425\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m     )\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# 假設你已經有 encoder (可凍結或可微調)\n",
        "# 這裡預設 freeze encoder\n",
        "for p in encoder.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# 建立 EmbeddingPredictor\n",
        "model = EmbeddingPredictor(\n",
        "    encoder=encoder,\n",
        "    embedding_dim=128,\n",
        "    hidden_dims=[256, 128, 64],\n",
        "    out_dim=1\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "num_epochs = 20\n",
        "best_val_loss = float('inf')  # 紀錄歷史最佳驗證損失\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "\n",
        "    # 1) train\n",
        "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "\n",
        "    # 2) validate\n",
        "    val_loss = eval_one_epoch(model, train_loader, criterion, device, desc=\"Valid\")\n",
        "\n",
        "    print(f\"  Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
        "\n",
        "    # 如果想 early stopping 或 save best model:\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        # 保存最佳參數\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        print(\"  (New best model saved!)\")\n",
        "\n",
        "# =============== 最後做 test =================\n",
        "# 載入最佳權重 (可選)\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "\n",
        "# 執行測試\n",
        "test_loss = eval_one_epoch(model, test_loader, criterion, device, desc=\"Test\")\n",
        "print(f\"Final Test Loss = {test_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bsOrOC0-L9T"
      },
      "source": [
        "##二元分類"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QvHbthIg5W0"
      },
      "source": [
        "embedding+MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGWH8vdPMj-r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class EmbeddingPredictor(nn.Module):\n",
        "    def __init__(self, encoder, embedding_dim=128, hidden_dims=None, out_dim=2):  # ⭐ out_dim=2\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "\n",
        "        if hidden_dims is None:\n",
        "            hidden_dims = [128,64]\n",
        "\n",
        "        layers = []\n",
        "        prev_dim = embedding_dim\n",
        "        for hd in hidden_dims:\n",
        "            layers.append(nn.Linear(prev_dim, hd))\n",
        "            layers.append(nn.ReLU())\n",
        "            prev_dim = hd\n",
        "\n",
        "        layers.append(nn.Linear(prev_dim, out_dim))  # ⭐ 輸出2個 logits\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            embedding = self.encoder(x.permute(0, 2, 1))  # [B, embedding_dim]\n",
        "        logits = self.mlp(embedding)  # [B, 2]\n",
        "        return logits\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCtl1Gs5g-WM"
      },
      "source": [
        "MLP only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY5N_H9PUXVi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FlattenMLP_BinaryCE(nn.Module):\n",
        "    def __init__(self, time_steps, feature_dim, hidden_dims=[128, 64], out_dim=2):\n",
        "        \"\"\"\n",
        "        time_steps: T\n",
        "        feature_dim: F\n",
        "        hidden_dims: list, e.g. [128,64]\n",
        "        out_dim=2 -> 二元分類 (class=0, class=1)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = time_steps * feature_dim\n",
        "        layers = []\n",
        "        prev_dim = self.input_dim\n",
        "\n",
        "        # 建立中間隱藏層\n",
        "        for hd in hidden_dims:\n",
        "            layers.append(nn.Linear(prev_dim, hd))\n",
        "            layers.append(nn.ReLU())\n",
        "            prev_dim = hd\n",
        "\n",
        "        # 最後一層 -> out_dim=2\n",
        "        layers.append(nn.Linear(prev_dim, out_dim))\n",
        "\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: shape = [B, T, F]\n",
        "        return: logits => [B, 2]\n",
        "        \"\"\"\n",
        "        B, T, F = x.shape\n",
        "        # flatten => [B, T*F]\n",
        "        x_flat = x.view(B, T * F)\n",
        "\n",
        "        # 透過 MLP 得到 logits => [B,2]\n",
        "        logits = self.mlp(x_flat)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6PguYwEhFZP"
      },
      "source": [
        "##將embedding加入為特徵"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pf9vbSinhBQn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class EmbeddingConcatPredictor(nn.Module):\n",
        "    def __init__(self, encoder, input_dim, seq_len, embedding_dim=128, hidden_dims=None, out_dim=2):\n",
        "        \"\"\"\n",
        "        - encoder: 提供抽取 embedding\n",
        "        - input_dim: 原始 feature 數 (31)\n",
        "        - seq_len: 時間長度 (32)\n",
        "        - embedding_dim: encoder 輸出向量維度 (128)\n",
        "        - hidden_dims: MLP 隱藏層設定\n",
        "        - out_dim: 預測類別數（默認2類）\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.input_dim = input_dim\n",
        "        self.seq_len = seq_len\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.flatten_dim = input_dim * seq_len\n",
        "        self.concat_dim = self.flatten_dim + embedding_dim\n",
        "\n",
        "        if hidden_dims is None:\n",
        "            hidden_dims = [256, 128]  # 根據 concat size 自訂義\n",
        "\n",
        "        layers = []\n",
        "        prev_dim = self.concat_dim\n",
        "        for hd in hidden_dims:\n",
        "            layers.append(nn.Linear(prev_dim, hd))\n",
        "            layers.append(nn.ReLU())\n",
        "            prev_dim = hd\n",
        "\n",
        "        layers.append(nn.Linear(prev_dim, out_dim))  # 最後輸出2類\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: shape (B, features, time) e.g., (B, 31, 32)\n",
        "        \"\"\"\n",
        "        B = x.size(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            embedding = self.encoder(x.permute(0, 2, 1))  # 取 embedding => (B, embedding_dim)\n",
        "\n",
        "        x_flatten = x.view(B, -1)  # 攤平成 (B, 31*32)\n",
        "\n",
        "        x_concat = torch.cat([x_flatten, embedding], dim=1)  # 合併成 (B, 31*32 + embedding_dim)\n",
        "\n",
        "        logits = self.mlp(x_concat)  # 送進 MLP 做分類\n",
        "        return logits  # logits (B, 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWib3egzgtoM"
      },
      "outputs": [],
      "source": [
        "##新的trainer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, optimizer, device,\n",
        "                 train_loader, val_loader=None,\n",
        "                 scheduler=None, save_path=None, early_stopping_patience=5):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.scheduler = scheduler\n",
        "        self.save_path = save_path\n",
        "        self.early_stopping_patience = early_stopping_patience\n",
        "\n",
        "        self.best_val_f1 = 0.0\n",
        "        self.early_stopping_counter = 0\n",
        "\n",
        "        if save_path:\n",
        "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    def train_one_epoch(self):\n",
        "        self.model.train()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        total_loss = 0.0\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        pbar = tqdm(self.train_loader, desc=\"Train\", leave=False)\n",
        "        for batch_x, batch_y in pbar:\n",
        "            batch_x = batch_x.to(self.device)\n",
        "            batch_y = batch_y.to(self.device).long()\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            logits = self.model(batch_x)\n",
        "            loss = criterion(logits, batch_y)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct = (preds == batch_y).sum().item()\n",
        "\n",
        "            total_correct += correct\n",
        "            total_samples += batch_y.size(0)\n",
        "\n",
        "            batch_acc = correct / batch_y.size(0)\n",
        "            pbar.set_postfix({\n",
        "                \"batch_loss\": f\"{loss.item():.4f}\",\n",
        "                \"batch_acc\":  f\"{batch_acc:.4f}\"\n",
        "            })\n",
        "\n",
        "        avg_loss = total_loss / len(self.train_loader)\n",
        "        avg_acc = total_correct / total_samples\n",
        "        return avg_loss, avg_acc\n",
        "\n",
        "    def eval_one_epoch(self, desc=\"Eval\"):\n",
        "        self.model.eval()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        total_loss = 0.0\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        all_preds = []\n",
        "        all_probs = []\n",
        "        all_labels = []\n",
        "\n",
        "        pbar = tqdm(self.val_loader, desc=desc, leave=False)\n",
        "        with torch.no_grad():\n",
        "            for batch_x, batch_y in pbar:\n",
        "                batch_x = batch_x.to(self.device)\n",
        "                batch_y = batch_y.to(self.device).long()\n",
        "\n",
        "                logits = self.model(batch_x)\n",
        "                loss = criterion(logits, batch_y)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                probs = torch.softmax(logits, dim=1)[:, 1]  # positive class probability\n",
        "                preds = logits.argmax(dim=1)\n",
        "\n",
        "                all_probs.append(probs.cpu())\n",
        "                all_preds.append(preds.cpu())\n",
        "                all_labels.append(batch_y.cpu())\n",
        "\n",
        "                correct = (preds == batch_y).sum().item()\n",
        "                total_correct += correct\n",
        "                total_samples += batch_y.size(0)\n",
        "\n",
        "                batch_acc = correct / batch_y.size(0)\n",
        "                pbar.set_postfix({\n",
        "                    \"batch_loss\": f\"{loss.item():.4f}\",\n",
        "                    \"batch_acc\":  f\"{batch_acc:.4f}\"\n",
        "                })\n",
        "\n",
        "        avg_loss = total_loss / len(self.val_loader)\n",
        "        avg_acc = total_correct / total_samples\n",
        "\n",
        "        all_preds = torch.cat(all_preds).numpy()\n",
        "        all_probs = torch.cat(all_probs).numpy()\n",
        "        all_labels = torch.cat(all_labels).numpy()\n",
        "\n",
        "        precision = precision_score(all_labels, all_preds)\n",
        "        recall = recall_score(all_labels, all_preds)\n",
        "        f1 = f1_score(all_labels, all_preds)\n",
        "        roc_auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "        return avg_loss, avg_acc, precision, recall, f1, roc_auc\n",
        "\n",
        "    def fit(self, num_epochs):\n",
        "        for epoch in range(1, num_epochs + 1):\n",
        "            print(f\"Epoch {epoch}/{num_epochs}\")\n",
        "\n",
        "            train_loss, train_acc = self.train_one_epoch()\n",
        "\n",
        "            if self.val_loader:\n",
        "                val_loss, val_acc, precision, recall, f1, roc_auc = self.eval_one_epoch()\n",
        "\n",
        "                # 如果 validation 有進步（以F1為基準）\n",
        "                if f1 > self.best_val_f1:\n",
        "                    self.best_val_f1 = f1\n",
        "                    self.early_stopping_counter = 0\n",
        "                    if self.save_path:\n",
        "                        torch.save(self.model.state_dict(), self.save_path)\n",
        "                        print(f\"✅ Saved new best model to {self.save_path}\")\n",
        "                else:\n",
        "                    self.early_stopping_counter += 1\n",
        "                    print(f\"⚠️ EarlyStopping Counter: {self.early_stopping_counter}/{self.early_stopping_patience}\")\n",
        "\n",
        "                # Early Stopping\n",
        "                if self.early_stopping_counter >= self.early_stopping_patience:\n",
        "                    print(\"⛔ Early stopping triggered!\")\n",
        "                    break\n",
        "\n",
        "                # Scheduler update\n",
        "                if self.scheduler:\n",
        "                    if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                        self.scheduler.step(val_loss)\n",
        "                    else:\n",
        "                        self.scheduler.step()\n",
        "\n",
        "                # 印出完整指標\n",
        "                print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "                print(f\"Val   Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "                print(f\"Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f} | ROC-AUC: {roc_auc:.4f}\")\n",
        "                print(\"-\" * 50)\n",
        "            else:\n",
        "                # 沒有 validation 的情況\n",
        "                print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "                print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl9KyWFhqkOR",
        "outputId": "c9f39460-e117-4753-f451-806b3df2de94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape = (92583, 32, 31)\n",
            "y_train.shape = (92583,)\n",
            "X_test.shape  = (21717, 32, 31)\n",
            "y_test.shape  = (21717,)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "# 讀取時\n",
        "data = np.load('/content/dataset_LSTM_binary.npz')\n",
        "X_train = data['X_train']\n",
        "y_train = data['y_train']\n",
        "X_test  = data['X_test']\n",
        "y_test  = data['y_test']\n",
        "\n",
        "print('X_train.shape =', X_train.shape)  # (samples_train, time_steps, features)\n",
        "print('y_train.shape =', y_train.shape)  # (samples_train,)\n",
        "print('X_test.shape  =', X_test.shape)   # (samples_test, time_steps, features)\n",
        "print('y_test.shape  =', y_test.shape)   # (samples_test,)\n",
        "\n",
        "t_mean = X_train.mean(axis=(0, 2), keepdims=True)  # shape: (1, features, 1)\n",
        "t_std = X_train.std(axis=(0, 2), keepdims=True)    # shape: (1, features, 1)\n",
        "v_mean = X_train.mean(axis=(0, 2), keepdims=True)  # shape: (1, features, 1)\n",
        "v_std = X_train.std(axis=(0, 2), keepdims=True)    # shape: (1, features, 1)\n",
        "# 正規化\n",
        "X_train_norm = (X_train - t_mean) / (t_std + 1e-8)\n",
        "X_val_norm = (X_test - v_mean) / (v_std + 1e-8)\n",
        "# 將 NumPy 陣列轉成 PyTorch tensor (float32)\n",
        "X_train_t = torch.from_numpy(X_train_norm.astype(np.float32))\n",
        "y_train_t = torch.from_numpy(y_train.astype(np.float32))\n",
        "\n",
        "X_test_t  = torch.from_numpy(X_val_norm.astype(np.float32))\n",
        "y_test_t  = torch.from_numpy(y_test.astype(np.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "9sf5c5BCh26D",
        "outputId": "351336fe-396e-4903-91b2-753affd24c08"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'SimSiamForTimeSeries' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-808591138ce5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;31m#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m31\u001b[0m  \u001b[0;31m# 特徵數\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msimsiam_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimSiamForTimeSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/checkpoint_epoch_8_2025-04-17_02-12-50ddpm_400-700.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msimsiam_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"simsiam_model_state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SimSiamForTimeSeries' is not defined"
          ]
        }
      ],
      "source": [
        "#emb+mlp\n",
        "device = 'cpu'#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_dim = 31  # 特徵數\n",
        "simsiam_model = SimSiamForTimeSeries(input_dim).to(device)\n",
        "checkpoint = torch.load('/content/checkpoint_epoch_8_2025-04-17_02-12-50ddpm_400-700.pt', map_location=device)\n",
        "simsiam_model.load_state_dict(checkpoint[\"simsiam_model_state_dict\"])\n",
        "encoder = simsiam_model.encoder\n",
        "for p in encoder.parameters():\n",
        "    p.requires_grad = False\n",
        "model = EmbeddingPredictor(\n",
        "    encoder=encoder,\n",
        "    embedding_dim=128,\n",
        "    hidden_dims=[256, 128, 64],\n",
        "    out_dim=2\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwlb3Lv_hn-y",
        "outputId": "80a87a00-d910-4f62-ac0d-5bfb23e1bb5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 將emb加入input\n",
        "device = 'cpu'\n",
        "simsiam_model = SimSiamForTimeSeries(31).to(device)\n",
        "checkpoint = torch.load('/content/checkpoint_epoch_13_2025-04-25_15-19-55tran_augment.pt', map_location=device)\n",
        "simsiam_model.load_state_dict(checkpoint[\"simsiam_model_state_dict\"])\n",
        "encoder = simsiam_model.encoder\n",
        "model = EmbeddingConcatPredictor(\n",
        "    encoder=encoder,\n",
        "    input_dim=31,\n",
        "    seq_len=32,\n",
        "    embedding_dim=128,\n",
        "    hidden_dims=[512, 256],\n",
        "    out_dim=2\n",
        ").to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-UTqSQTivcS"
      },
      "outputs": [],
      "source": [
        "# (B) 建構 FlattenMLP_BinaryCE\n",
        "model = FlattenMLP_BinaryCE(\n",
        "    time_steps=32,\n",
        "    feature_dim=31,\n",
        "    hidden_dims=[128,64],\n",
        "    out_dim=2  # 二分類 => 2\n",
        ").to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsxBmpTZYr80",
        "outputId": "55d78841-1891-4803-c56a-fc262defc849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model to ./checkpoints/best_model.pth\n",
            "Train Loss: 1.2622 | Train Acc: 0.8582\n",
            "Val   Loss: 1.3155 | Val Acc: 0.7079\n",
            "Precision: 0.7878 | Recall: 0.6681 | F1: 0.7230 | ROC-AUC: 0.7612\n",
            "--------------------------------------------------\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model to ./checkpoints/best_model.pth\n",
            "Train Loss: 0.2405 | Train Acc: 0.9005\n",
            "Val   Loss: 2.2422 | Val Acc: 0.7034\n",
            "Precision: 0.7707 | Recall: 0.6835 | F1: 0.7245 | ROC-AUC: 0.7770\n",
            "--------------------------------------------------\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model to ./checkpoints/best_model.pth\n",
            "Train Loss: 0.2261 | Train Acc: 0.9065\n",
            "Val   Loss: 1.3048 | Val Acc: 0.7136\n",
            "Precision: 0.7907 | Recall: 0.6775 | F1: 0.7297 | ROC-AUC: 0.7958\n",
            "--------------------------------------------------\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model to ./checkpoints/best_model.pth\n",
            "Train Loss: 0.1672 | Train Acc: 0.9301\n",
            "Val   Loss: 1.4941 | Val Acc: 0.7146\n",
            "Precision: 0.7725 | Recall: 0.7085 | F1: 0.7391 | ROC-AUC: 0.7889\n",
            "--------------------------------------------------\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model to ./checkpoints/best_model.pth\n",
            "Train Loss: 0.1962 | Train Acc: 0.9221\n",
            "Val   Loss: 1.9612 | Val Acc: 0.7033\n",
            "Precision: 0.7378 | Recall: 0.7448 | F1: 0.7413 | ROC-AUC: 0.7592\n",
            "--------------------------------------------------\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model to ./checkpoints/best_model.pth\n",
            "Train Loss: 0.2352 | Train Acc: 0.8928\n",
            "Val   Loss: 2.8648 | Val Acc: 0.7241\n",
            "Precision: 0.7532 | Recall: 0.7683 | F1: 0.7607 | ROC-AUC: 0.7854\n",
            "--------------------------------------------------\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 1/5\n",
            "Train Loss: 0.1771 | Train Acc: 0.9370\n",
            "Val   Loss: 1.8611 | Val Acc: 0.7251\n",
            "Precision: 0.7944 | Recall: 0.6994 | F1: 0.7439 | ROC-AUC: 0.7980\n",
            "--------------------------------------------------\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 2/5\n",
            "Train Loss: 0.1634 | Train Acc: 0.9334\n",
            "Val   Loss: 4.4843 | Val Acc: 0.7131\n",
            "Precision: 0.7636 | Recall: 0.7202 | F1: 0.7413 | ROC-AUC: 0.7748\n",
            "--------------------------------------------------\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 3/5\n",
            "Train Loss: 0.1465 | Train Acc: 0.9263\n",
            "Val   Loss: 3.5406 | Val Acc: 0.7321\n",
            "Precision: 0.7861 | Recall: 0.7289 | F1: 0.7564 | ROC-AUC: 0.7893\n",
            "--------------------------------------------------\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 4/5\n",
            "Train Loss: 0.1497 | Train Acc: 0.9342\n",
            "Val   Loss: 2.8980 | Val Acc: 0.7256\n",
            "Precision: 0.7757 | Recall: 0.7303 | F1: 0.7523 | ROC-AUC: 0.7826\n",
            "--------------------------------------------------\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model to ./checkpoints/best_model.pth\n",
            "Train Loss: 0.1209 | Train Acc: 0.9482\n",
            "Val   Loss: 8.2710 | Val Acc: 0.7360\n",
            "Precision: 0.7327 | Recall: 0.8460 | F1: 0.7853 | ROC-AUC: 0.7813\n",
            "--------------------------------------------------\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 1/5\n",
            "Train Loss: 0.1609 | Train Acc: 0.9425\n",
            "Val   Loss: 3.4035 | Val Acc: 0.7019\n",
            "Precision: 0.7596 | Recall: 0.6988 | F1: 0.7279 | ROC-AUC: 0.7611\n",
            "--------------------------------------------------\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 2/5\n",
            "Train Loss: 0.1541 | Train Acc: 0.9480\n",
            "Val   Loss: 7.8411 | Val Acc: 0.7085\n",
            "Precision: 0.7573 | Recall: 0.7198 | F1: 0.7381 | ROC-AUC: 0.7588\n",
            "--------------------------------------------------\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 3/5\n",
            "Train Loss: 0.1399 | Train Acc: 0.9541\n",
            "Val   Loss: 1.7921 | Val Acc: 0.7200\n",
            "Precision: 0.7592 | Recall: 0.7461 | F1: 0.7526 | ROC-AUC: 0.7748\n",
            "--------------------------------------------------\n",
            "Epoch 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 4/5\n",
            "Train Loss: 0.1466 | Train Acc: 0.9451\n",
            "Val   Loss: 4.9792 | Val Acc: 0.6729\n",
            "Precision: 0.7713 | Recall: 0.6067 | F1: 0.6792 | ROC-AUC: 0.7639\n",
            "--------------------------------------------------\n",
            "Epoch 16/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 5/5\n",
            "⛔ Early stopping triggered!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "#700\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "test_dataset  = TensorDataset(X_test_t,  y_test_t)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False)\n",
        "\n",
        "# (C) Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "# 假設你已經有這些：\n",
        "# model, optimizer, train_loader, val_loader\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=test_loader,\n",
        "    scheduler=None,  # 如果有學習率調整器也可以放\n",
        "    save_path=\"./checkpoints/best_model.pth\",\n",
        "    early_stopping_patience=5\n",
        ")\n",
        "\n",
        "# 開始訓練\n",
        "trainer.fit(num_epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ASlkLrzi8jG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d88d4a3f-3cff-4dfe-8725-649cca4eebe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model to ./checkpoints/best_model.pth\n",
            "Train Loss: 1.6160 | Train Acc: 0.8657\n",
            "Val   Loss: 1.6534 | Val Acc: 0.6843\n",
            "Precision: 0.7785 | Recall: 0.6243 | F1: 0.6929 | ROC-AUC: 0.7317\n",
            "--------------------------------------------------\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model to ./checkpoints/best_model.pth\n",
            "Train Loss: 0.2414 | Train Acc: 0.9075\n",
            "Val   Loss: 1.6870 | Val Acc: 0.7278\n",
            "Precision: 0.7658 | Recall: 0.7534 | F1: 0.7595 | ROC-AUC: 0.7656\n",
            "--------------------------------------------------\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model to ./checkpoints/best_model.pth\n",
            "Train Loss: 0.2117 | Train Acc: 0.9160\n",
            "Val   Loss: 1.7005 | Val Acc: 0.7450\n",
            "Precision: 0.7616 | Recall: 0.8051 | F1: 0.7828 | ROC-AUC: 0.7622\n",
            "--------------------------------------------------\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 1/5\n",
            "Train Loss: 0.1958 | Train Acc: 0.9282\n",
            "Val   Loss: 1.6353 | Val Acc: 0.7319\n",
            "Precision: 0.7761 | Recall: 0.7452 | F1: 0.7603 | ROC-AUC: 0.7760\n",
            "--------------------------------------------------\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 2/5\n",
            "Train Loss: 0.1608 | Train Acc: 0.9368\n",
            "Val   Loss: 1.5511 | Val Acc: 0.7111\n",
            "Precision: 0.7829 | Recall: 0.6831 | F1: 0.7296 | ROC-AUC: 0.7779\n",
            "--------------------------------------------------\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 3/5\n",
            "Train Loss: 0.1720 | Train Acc: 0.9348\n",
            "Val   Loss: 2.0305 | Val Acc: 0.7320\n",
            "Precision: 0.7596 | Recall: 0.7759 | F1: 0.7677 | ROC-AUC: 0.7669\n",
            "--------------------------------------------------\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model to ./checkpoints/best_model.pth\n",
            "Train Loss: 0.1615 | Train Acc: 0.9364\n",
            "Val   Loss: 2.6631 | Val Acc: 0.7643\n",
            "Precision: 0.7818 | Recall: 0.8142 | F1: 0.7977 | ROC-AUC: 0.7887\n",
            "--------------------------------------------------\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 1/5\n",
            "Train Loss: 0.1641 | Train Acc: 0.9443\n",
            "Val   Loss: 5.6687 | Val Acc: 0.7135\n",
            "Precision: 0.7869 | Recall: 0.6827 | F1: 0.7311 | ROC-AUC: 0.7832\n",
            "--------------------------------------------------\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model to ./checkpoints/best_model.pth\n",
            "Train Loss: 0.1774 | Train Acc: 0.9410\n",
            "Val   Loss: 5.8798 | Val Acc: 0.7519\n",
            "Precision: 0.7235 | Recall: 0.9150 | F1: 0.8080 | ROC-AUC: 0.7560\n",
            "--------------------------------------------------\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 1/5\n",
            "Train Loss: 0.1315 | Train Acc: 0.9464\n",
            "Val   Loss: 2.3389 | Val Acc: 0.7653\n",
            "Precision: 0.7936 | Recall: 0.7957 | F1: 0.7946 | ROC-AUC: 0.7915\n",
            "--------------------------------------------------\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 2/5\n",
            "Train Loss: 0.1751 | Train Acc: 0.9398\n",
            "Val   Loss: 9.7727 | Val Acc: 0.7501\n",
            "Precision: 0.7575 | Recall: 0.8266 | F1: 0.7906 | ROC-AUC: 0.7613\n",
            "--------------------------------------------------\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 3/5\n",
            "Train Loss: 0.1634 | Train Acc: 0.9403\n",
            "Val   Loss: 2.9036 | Val Acc: 0.6962\n",
            "Precision: 0.7998 | Recall: 0.6237 | F1: 0.7009 | ROC-AUC: 0.7863\n",
            "--------------------------------------------------\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 4/5\n",
            "Train Loss: 0.1427 | Train Acc: 0.9529\n",
            "Val   Loss: 4.6599 | Val Acc: 0.7283\n",
            "Precision: 0.7883 | Recall: 0.7162 | F1: 0.7505 | ROC-AUC: 0.7773\n",
            "--------------------------------------------------\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 5/5\n",
            "⛔ Early stopping triggered!\n"
          ]
        }
      ],
      "source": [
        "#500\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "test_dataset  = TensorDataset(X_test_t,  y_test_t)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False)\n",
        "\n",
        "# (C) Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "# 假設你已經有這些：\n",
        "# model, optimizer, train_loader, val_loader\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=test_loader,\n",
        "    scheduler=None,  # 如果有學習率調整器也可以放\n",
        "    save_path=\"./checkpoints/best_model.pth\",\n",
        "    early_stopping_patience=5\n",
        ")\n",
        "\n",
        "# 開始訓練\n",
        "trainer.fit(num_epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trandition\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "test_dataset  = TensorDataset(X_test_t,  y_test_t)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False)\n",
        "\n",
        "# (C) Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "# 假設你已經有這些：\n",
        "# model, optimizer, train_loader, val_loader\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=test_loader,\n",
        "    scheduler=None,  # 如果有學習率調整器也可以放\n",
        "    save_path=\"./checkpoints/best_model.pth\",\n",
        "    early_stopping_patience=5\n",
        ")\n",
        "\n",
        "# 開始訓練\n",
        "trainer.fit(num_epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1v2HR1P7t4d",
        "outputId": "c93a38e2-cc3b-4efa-de9d-6063c117ae16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model to ./checkpoints/best_model.pth\n",
            "Train Loss: 0.2635 | Train Acc: 0.8807\n",
            "Val   Loss: 1.1603 | Val Acc: 0.7078\n",
            "Precision: 0.7432 | Recall: 0.7457 | F1: 0.7445 | ROC-AUC: 0.7470\n",
            "--------------------------------------------------\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 1/5\n",
            "Train Loss: 0.1552 | Train Acc: 0.9370\n",
            "Val   Loss: 1.4278 | Val Acc: 0.6937\n",
            "Precision: 0.7514 | Recall: 0.6924 | F1: 0.7207 | ROC-AUC: 0.7474\n",
            "--------------------------------------------------\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 2/5\n",
            "Train Loss: 0.1279 | Train Acc: 0.9478\n",
            "Val   Loss: 1.4183 | Val Acc: 0.6964\n",
            "Precision: 0.7456 | Recall: 0.7103 | F1: 0.7276 | ROC-AUC: 0.7497\n",
            "--------------------------------------------------\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 3/5\n",
            "Train Loss: 0.1113 | Train Acc: 0.9542\n",
            "Val   Loss: 1.9330 | Val Acc: 0.6768\n",
            "Precision: 0.7549 | Recall: 0.6421 | F1: 0.6940 | ROC-AUC: 0.7547\n",
            "--------------------------------------------------\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 4/5\n",
            "Train Loss: 0.1025 | Train Acc: 0.9585\n",
            "Val   Loss: 1.8385 | Val Acc: 0.6552\n",
            "Precision: 0.7378 | Recall: 0.6140 | F1: 0.6702 | ROC-AUC: 0.7360\n",
            "--------------------------------------------------\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ EarlyStopping Counter: 5/5\n",
            "⛔ Early stopping triggered!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}